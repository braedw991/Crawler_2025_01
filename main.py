from crawler.vnexpress_crawler import crawl_articles_by_category_and_date
from exporter.pdf_exporter import export_pdf
from integrations.google_drive_uploader import upload_to_drive
from database.db_manager import save_articles, load_articles
from config.settings import CATEGORIES, BASE_URL
import os
from datetime import datetime
import sys
import traceback

# Th√™m ƒë∆∞·ªùng d·∫´n g·ªëc c·ªßa d·ª± √°n v√†o sys.path ƒë·ªÉ import ho·∫°t ƒë·ªông ·ªïn ƒë·ªãnh
# ƒêi·ªÅu n√†y r·∫•t quan tr·ªçng ƒë·ªÉ tr√°nh c√°c l·ªói ImportError trong c√°c m√¥i tr∆∞·ªùng kh√°c nhau
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

# L·∫•y ID th∆∞ m·ª•c Drive t·ª´ bi·∫øn m√¥i tr∆∞·ªùng
DRIVE_FOLDER_ID = os.getenv("DRIVE_FOLDER_ID")

def select_category():
    """Hi·ªÉn th·ªã danh s√°ch chuy√™n m·ª•c v√† cho ph√©p ng∆∞·ªùi d√πng ch·ªçn."""
    print("\n--- Vui l√≤ng ch·ªçn chuy√™n m·ª•c ƒë·ªÉ crawl ---")
    category_list = list(CATEGORIES.keys())
    for i, name in enumerate(category_list):
        print(f"{i + 1}. {name}")
    
    while True:
        try:
            choice_str = input(f"\n‚û°Ô∏è  Nh·∫≠p l·ª±a ch·ªçn c·ªßa b·∫°n (1-{len(category_list)}): ")
            if not choice_str: continue
            choice = int(choice_str)
            if 1 <= choice <= len(category_list):
                return category_list[choice - 1]
            else:
                print("‚ùå L·ª±a ch·ªçn kh√¥ng h·ª£p l·ªá, vui l√≤ng nh·∫≠p l·∫°i.")
        except ValueError:
            print("‚ùå Vui l√≤ng nh·∫≠p m·ªôt con s·ªë.")

def get_target_date():
    """Cho ph√©p ng∆∞·ªùi d√πng nh·∫≠p ng√†y ho·∫∑c d√πng ng√†y h√¥m nay."""
    while True:
        date_str = input("üóìÔ∏è  Nh·∫≠p ng√†y mu·ªën crawl (DD-MM-YYYY), ho·∫∑c ƒë·ªÉ tr·ªëng ƒë·ªÉ l·∫•y ng√†y h√¥m nay: ").strip()
        if not date_str:
            target_date = datetime.now()
            print(f"‚úÖ S·ª≠ d·ª•ng ng√†y h√¥m nay: {target_date.strftime('%d-%m-%Y')}")
            return target_date
        else:
            try:
                return datetime.strptime(date_str, "%d-%m-%Y")
            except ValueError:
                print("‚ùå ƒê·ªãnh d·∫°ng ng√†y kh√¥ng h·ª£p l·ªá. Vui l√≤ng d√πng DD-MM-YYYY.")

def main():
    """Quy tr√¨nh t·ª± ƒë·ªông h√≥a ch√≠nh."""
    # 1. D·ªçn d·∫πp d·ªØ li·ªáu c≈© ƒë·ªÉ b·∫Øt ƒë·∫ßu phi√™n l√†m vi·ªác m·ªõi
    save_articles([]) # T·∫°o ra file articles.json r·ªóng
    print("üßπ ƒê√£ d·ªçn d·∫πp d·ªØ li·ªáu c≈©, s·∫µn s√†ng cho phi√™n l√†m vi·ªác m·ªõi.")

    # 2. L·∫•y th√¥ng tin t·ª´ ng∆∞·ªùi d√πng
    category_name = select_category()
    target_date = get_target_date()

    # 3. Ch·∫°y Crawler
    crawl_articles_by_category_and_date(category_name, target_date)

    # Ki·ªÉm tra xem c√≥ b√†i vi·∫øt n√†o ƒë∆∞·ª£c crawl kh√¥ng
    if not load_articles():
        print("\n‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y b√†i vi·∫øt n√†o cho chuy√™n m·ª•c v√† ng√†y ƒë√£ ch·ªçn. K·∫øt th√∫c ch∆∞∆°ng tr√¨nh.")
        return

    # 4. Xu·∫•t file PDF
    print("\n--- B·∫Øt ƒë·∫ßu xu·∫•t file PDF ---")
    actual_pdf_path = export_pdf(category_name, target_date, limit=None)

    # 5. T·∫£i l√™n Google Drive
    if actual_pdf_path and os.path.exists(actual_pdf_path):
        if DRIVE_FOLDER_ID:
            print("\n--- B·∫Øt ƒë·∫ßu t·∫£i l√™n Google Drive ---")
            upload_to_drive(actual_pdf_path, DRIVE_FOLDER_ID)
        else:
            print("\n‚ö†Ô∏è  B·ªè qua t·∫£i l√™n Drive: Bi·∫øn m√¥i tr∆∞·ªùng DRIVE_FOLDER_ID ch∆∞a ƒë∆∞·ª£c c·∫•u h√¨nh trong file .env")
    else:
        print(f"\n‚ö†Ô∏è  B·ªè qua t·∫£i l√™n Drive: File PDF kh√¥ng ƒë∆∞·ª£c t·∫°o ho·∫∑c kh√¥ng t√¨m th·∫•y.")
    
    print("\nüéâüéâüéâ QUY TR√åNH HO√ÄN T·∫§T! üéâüéâüéâ")

if __name__ == "__main__":
    main()
